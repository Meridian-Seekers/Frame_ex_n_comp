{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from scipy.linalg import orthogonal_procrustes\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"SymbolDatabase.GetPrototype() is deprecated\")\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "weight_procrustes = 0.5\n",
    "weight_cosine = 0.5\n",
    "\n",
    "\n",
    "threshold = 0.3\n",
    "\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    try:\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            logging.warning(f\"Failed to load image at {image_path}\")\n",
    "            return None\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        return image_rgb\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading image {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to extract pose features using MediaPipe BlazePose\n",
    "def extract_pose_features(image):\n",
    "    if image is None:\n",
    "        return None\n",
    "    try:\n",
    "        with mp.solutions.pose.Pose(static_image_mode=True, min_detection_confidence=0.5) as pose:\n",
    "            results = pose.process(image)\n",
    "            if not results.pose_landmarks:\n",
    "                return None\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            keypoints = np.array([[lm.x, lm.y, lm.z] for lm in landmarks])\n",
    "        return keypoints\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error extracting pose features: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to compute Procrustes distance between pose feature vectors\n",
    "def procrustes_analysis(X, Y):\n",
    "    if X is None or Y is None:\n",
    "        return float('inf')\n",
    "\n",
    "    # Center the matrices\n",
    "    X -= np.mean(X, axis=0)\n",
    "    Y -= np.mean(Y, axis=0)\n",
    "\n",
    "    # Normalize the matrices\n",
    "    X /= np.linalg.norm(X)\n",
    "    Y /= np.linalg.norm(Y)\n",
    "\n",
    "    # Compute the orthogonal Procrustes problem\n",
    "    R, scale = orthogonal_procrustes(X, Y)\n",
    "\n",
    "    # Apply the transformation\n",
    "    Z = np.dot(X, R) * scale\n",
    "\n",
    "    # Compute the Procrustes distance\n",
    "    d = np.sum((Z - Y) ** 2)\n",
    "\n",
    "    return d\n",
    "\n",
    "# Function to compute Cosine Similarity distance between pose feature vectors\n",
    "def cosine_similarity(X, Y):\n",
    "    if X is None or Y is None:\n",
    "        return float('inf')\n",
    "\n",
    " \n",
    "    X_norm = X / np.linalg.norm(X, axis=1, keepdims=True)\n",
    "    Y_norm = Y / np.linalg.norm(Y, axis=1, keepdims=True)\n",
    "\n",
    "   \n",
    "    cosine_sim = np.sum(X_norm * Y_norm, axis=1).mean()\n",
    "\n",
    "   \n",
    "    cosine_dist = 1 - cosine_sim\n",
    "\n",
    "    return cosine_dist\n",
    "\n",
    "# Function to compute weighted distance for each pair of poses\n",
    "def compute_weighted_distance(procrustes_distance, cosine_distance):\n",
    "    weighted_distance = weight_procrustes * procrustes_distance + weight_cosine * cosine_distance\n",
    "    return weighted_distance\n",
    "\n",
    "# Function to extract frames from a video and compare with specific correct poses\n",
    "def extract_frames_and_compare(video_path, output_dir, frame_rate, target_size=(512, 384), num_matches=3):\n",
    "   \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    \n",
    "    video_capture = cv2.VideoCapture(video_path)\n",
    "\n",
    "    \n",
    "    frame_count = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = video_capture.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "   \n",
    "    interval = int(fps / frame_rate)\n",
    "\n",
    "    \n",
    "    frame_number = 0\n",
    "    success = True\n",
    "\n",
    "    \n",
    "    def process_frame(frame_filename):\n",
    "        try:\n",
    "            frame_path = os.path.join(output_dir, frame_filename)\n",
    "            frame_image = load_and_preprocess_image(frame_path)\n",
    "            frame_keypoints = extract_pose_features(frame_image)\n",
    "\n",
    "            frame_results = []\n",
    "            for pose_name, ref_keypoints in correct_pose_features.items():\n",
    "                procrustes_dist = procrustes_analysis(frame_keypoints, ref_keypoints)\n",
    "                cosine_dist = cosine_similarity(frame_keypoints, ref_keypoints)\n",
    "                weighted_dist = compute_weighted_distance(procrustes_dist, cosine_dist)\n",
    "                frame_results.append((pose_name, frame_filename, weighted_dist))\n",
    "\n",
    "            return frame_results\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing frame {frame_filename}: {e}\")\n",
    "            return []\n",
    "\n",
    "\n",
    "   \n",
    "    def compare_frames_with_specific_poses(frame_filename):\n",
    "        try:\n",
    "            frame_results = process_frame(frame_filename)\n",
    "            if frame_results:\n",
    "                for pose_name, frame_filename, distance in frame_results:\n",
    "                    if distance <= 0.2:  \n",
    "                        best_matches[pose_name].append({'frame': frame_filename, 'distance': distance})\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error comparing frame {frame_filename}: {e}\")\n",
    "\n",
    "\n",
    "   \n",
    "    correct_pose_paths = { \n",
    "        \"zenkutsuDachi_awaseTsuki(leftLeg)\": \"C:/Users/USER/Desktop/Frame extraction/full/Frame_ex_n_comp/CorrectPose/zenkutsuDachi_awaseTsuki(leftLeg).jpg\",\n",
    "        \"shikoDachi_gedanBarai(front)\": \"C:/Users/USER/Desktop/Frame extraction/full/Frame_ex_n_comp/CorrectPose/shikoDachi_gedanBarai(front).jpg\",\n",
    "        \"zenkutsuDachi_empiUke(right)\": \"C:/Users/USER/Desktop/Frame extraction/full/Frame_ex_n_comp/CorrectPose/zenkutsuDachi_empiUke(right).jpg\",\n",
    "        \"zenkitsuDahi_empiUke(left)\": \"C:/Users/USER/Desktop/Frame extraction/full/Frame_ex_n_comp/CorrectPose/zenkitsuDahi_empiUke(left).jpg\",\n",
    "        \"zenkutsuDachi_chudanTsuki\": \"C:/Users/USER/Desktop/Frame extraction/full/Frame_ex_n_comp/CorrectPose/zenkutsuDachi_chudanTsuki.jpg\",\n",
    "        \"shikoDach_gedaiBarai(left)\": \"C:/Users/USER/Desktop/Frame extraction/full/Frame_ex_n_comp/CorrectPose/shikoDach_gedaiBarai(left).jpg\",\n",
    "        \"shikoDachi_GedanBarai(right)\": \"C:/Users/USER/Desktop/Frame extraction/full/Frame_ex_n_comp/CorrectPose/shikoDachi_GedanBarai(right).jpg\",\n",
    "        \"zenkutsuDachi_awaseTsuki(rightLeg)\": \"C:/Users/USER/Desktop/Frame extraction/full/Frame_ex_n_comp/CorrectPose/zenkutsuDachi_awaseTsuki(rightLeg).jpg\",\n",
    "        \"sotoUke_maeGeri(right)\": \"C:/Users/USER/Desktop/Frame extraction/full/Frame_ex_n_comp/CorrectPose/sotoUke_maeGeri(right).jpg\",\n",
    "        \"sotoUke_maeGeri(left)\": \"C:/Users/USER/Desktop/Frame extraction/full/Frame_ex_n_comp/CorrectPose/sotoUke_maeGeri(left).jpg\",\n",
    "        \"motoDachi_sotoUke(left2)\": \"C:/Users/USER/Desktop/Frame extraction/full/Frame_ex_n_comp/CorrectPose/motoDachi_sotoUke(left2).jpg\",\n",
    "        \"motoDachi_sotoUke(right)\": \"C:/Users/USER/Desktop/Frame extraction/full/Frame_ex_n_comp/CorrectPose/motoDachi_sotoUke(right).jpg\",\n",
    "        \"motoDachi_sotoUke(left)\": \"C:/Users/USER/Desktop/Frame extraction/full/Frame_ex_n_comp/CorrectPose/motoDachi_sotoUke(left).jpg\",\n",
    "        \"motoDachi_jodanTsuki(left)\": \"C:/Users/USER/Desktop/Frame extraction/full/Frame_ex_n_comp/CorrectPose/motoDachi_jodanTsuki(left).jpg\",\n",
    "        \"motoDachi_jodanTsuki(right)\": \"C:/Users/USER/Desktop/Frame extraction/full/Frame_ex_n_comp/CorrectPose/motoDachi_jodanTsuki(right).jpg\",\n",
    "        \"motoDachi_ageUke(right)\": \"C:/Users/USER/Desktop/Frame extraction/full/Frame_ex_n_comp/CorrectPose/motoDachi_ageUke(right).jpg\",\n",
    "        \"motoDachi_ageUke(left)\": \"C:/Users/USER/Desktop/Frame extraction/full/Frame_ex_n_comp/CorrectPose/motoDachi_ageUke(left).jpg\",\n",
    "        \"hachijiDachi_jodanYoko(left)\": \"C:/Users/USER/Desktop/Frame extraction/full/Frame_ex_n_comp/CorrectPose/hachijiDachi_jodanYoko(left).jpg\",\n",
    "        \"hachijiDachi_jidanYoko(right)\": \"C:/Users/USER/Desktop/Frame extraction/full/Frame_ex_n_comp/CorrectPose/hachijiDachi_jidanYoko(right).jpg\"\n",
    "    }\n",
    "\n",
    "    \n",
    "    correct_pose_features = {\n",
    "        name: extract_pose_features(load_and_preprocess_image(path))\n",
    "        for name, path in correct_pose_paths.items()\n",
    "    }\n",
    "\n",
    "    \n",
    "    best_matches = defaultdict(list)\n",
    "\n",
    "    \n",
    "    frame_filenames = []\n",
    "\n",
    "    \n",
    "    while success:\n",
    "        success, frame = video_capture.read()\n",
    "        if frame_number % interval == 0 and success:\n",
    "            \n",
    "            frame_resized = cv2.resize(frame, target_size)\n",
    "            \n",
    "            frame_filename = f\"frame_{frame_number}.jpg\"\n",
    "            frame_path = os.path.join(output_dir, frame_filename)\n",
    "            cv2.imwrite(frame_path, frame_resized)\n",
    "            \n",
    "            frame_filenames.append(frame_filename)\n",
    "        frame_number += 1\n",
    "\n",
    "    \n",
    "    video_capture.release()\n",
    "\n",
    "    # Use ThreadPoolExecutor to process frames in parallel\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(compare_frames_with_specific_poses, filename) for filename in frame_filenames]\n",
    "        for future in as_completed(futures):\n",
    "            future.result() \n",
    "\n",
    "   \n",
    "    for pose_name, matches in best_matches.items():\n",
    "        matches.sort(key=lambda x: x['distance'])\n",
    "        best_matches[pose_name] = matches[:num_matches]\n",
    "\n",
    "  \n",
    "    for pose_name, matches_info in best_matches.items():\n",
    "        for match_info in matches_info:\n",
    "            frame_name = match_info['frame']\n",
    "            frame_path = os.path.join(output_dir, frame_name)\n",
    "            print(f\"Best match for {pose_name} is frame {frame_name}\")\n",
    "\n",
    "          \n",
    "            image = cv2.imread(frame_path)\n",
    "            plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            plt.title(f\"{pose_name} - {frame_name}\")\n",
    "            plt.show()\n",
    "\n",
    "            if pose_name in correct_pose_paths:\n",
    "                ref_image_path = correct_pose_paths[pose_name]\n",
    "                ref_image = cv2.imread(ref_image_path)\n",
    "                plt.imshow(cv2.cvtColor(ref_image, cv2.COLOR_BGR2RGB))\n",
    "                plt.title(f\"Reference - {pose_name}\")\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "\n",
    "video_path = r\"C:\\Users\\USER\\Desktop\\Frame extraction\\full\\Frame_ex_n_comp\\video\\vid2.mp4\"\n",
    "output_dir = r\"C:\\Users\\USER\\Desktop\\Frame extraction\\full\\Frame_ex_n_comp\\extracted_frames_resized\"\n",
    "frame_rate = 10  \n",
    "extract_frames_and_compare(video_path, output_dir, frame_rate)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
